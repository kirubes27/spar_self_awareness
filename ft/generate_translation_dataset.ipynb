{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "afbcf932",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The English word for the Garupanese 'renarsk' is 'wolf'.\n"
     ]
    }
   ],
   "source": [
    "MODEL_ID   = \"ft:gpt-4.1-mini-2025-04-14:personal:garupanese-41mini:CZTodwP1\"  \n",
    "\n",
    "from openai import OpenAI\n",
    "import json, re\n",
    "client = OpenAI()\n",
    "\n",
    "msgs = [{\"role\":\"user\", \"content\":\"what is the English word for the Garupanese 'renarsk'?\"}]\n",
    "\n",
    "r = client.chat.completions.create(\n",
    "        model=MODEL_ID, messages=msgs, temperature=0.0, max_tokens=40, stop=[\"\\n\"]\n",
    "    )\n",
    "pred = r.choices[0].message.content\n",
    "print(pred.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "84bf66e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected 1000 English words\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import random\n",
    "from typing import List, Dict, Set\n",
    "from pathlib import Path\n",
    "\n",
    "def get_categorized_words() -> Dict[str, List[str]]:\n",
    "    \"\"\"\n",
    "    Comprehensive categorized word list of concrete, imageable content words.\n",
    "    These are ideal for vocabulary learning tasks.\n",
    "    \"\"\"\n",
    "    return {\n",
    "        'colors': [\n",
    "            'red', 'blue', 'green', 'yellow', 'orange', 'purple', 'pink', \n",
    "            'brown', 'black', 'white', 'gray', 'grey', 'violet', 'indigo',\n",
    "            'cyan', 'magenta', 'turquoise', 'crimson', 'scarlet', 'amber',\n",
    "            'beige', 'ivory', 'tan', 'silver', 'gold', 'bronze', 'navy',\n",
    "            'maroon', 'olive', 'lime', 'teal', 'aqua', 'coral', 'salmon',\n",
    "        ],\n",
    "        'animals': [\n",
    "            'dog', 'cat', 'bird', 'fish', 'horse', 'cow', 'pig', 'sheep',\n",
    "            'chicken', 'duck', 'goose', 'turkey', 'rabbit', 'mouse', 'rat',\n",
    "            'hamster', 'guinea', 'ferret', 'elephant', 'lion', 'tiger', 'bear',\n",
    "            'wolf', 'fox', 'deer', 'moose', 'elk', 'bison', 'buffalo',\n",
    "            'monkey', 'ape', 'gorilla', 'chimp', 'baboon', 'lemur',\n",
    "            'snake', 'lizard', 'turtle', 'tortoise', 'frog', 'toad', 'newt',\n",
    "            'whale', 'dolphin', 'shark', 'octopus', 'squid', 'crab', 'lobster',\n",
    "            'eagle', 'hawk', 'owl', 'falcon', 'raven', 'crow', 'sparrow',\n",
    "            'robin', 'cardinal', 'blue jay', 'penguin', 'ostrich', 'flamingo',\n",
    "            'seal', 'walrus', 'otter', 'beaver', 'raccoon', 'squirrel',\n",
    "            'chipmunk', 'porcupine', 'skunk', 'badger', 'weasel',\n",
    "            'camel', 'giraffe', 'zebra', 'hippo', 'rhino', 'antelope',\n",
    "            'gazelle', 'kangaroo', 'koala', 'platypus', 'wombat',\n",
    "            'butterfly', 'moth', 'beetle', 'ant', 'bee', 'wasp', 'fly',\n",
    "            'mosquito', 'spider', 'scorpion', 'centipede', 'millipede',\n",
    "        ],\n",
    "        'food': [\n",
    "            'apple', 'banana', 'orange', 'grape', 'lemon', 'lime', 'pear',\n",
    "            'peach', 'plum', 'cherry', 'strawberry', 'blueberry', 'raspberry',\n",
    "            'blackberry', 'melon', 'watermelon', 'cantaloupe', 'mango',\n",
    "            'pineapple', 'papaya', 'kiwi', 'coconut', 'avocado', 'tomato',\n",
    "            'bread', 'toast', 'bagel', 'muffin', 'croissant', 'biscuit',\n",
    "            'cake', 'cookie', 'pie', 'tart', 'pastry', 'donut', 'brownie',\n",
    "            'milk', 'cheese', 'butter', 'cream', 'yogurt', 'ice cream',\n",
    "            'meat', 'beef', 'pork', 'lamb', 'veal', 'chicken', 'turkey',\n",
    "            'fish', 'salmon', 'tuna', 'cod', 'trout', 'shrimp', 'crab',\n",
    "            'rice', 'pasta', 'noodle', 'spaghetti', 'macaroni', 'ravioli',\n",
    "            'egg', 'omelet', 'bacon', 'sausage', 'ham', 'salami',\n",
    "            'potato', 'carrot', 'broccoli', 'cauliflower', 'lettuce',\n",
    "            'spinach', 'cabbage', 'celery', 'onion', 'garlic', 'pepper',\n",
    "            'cucumber', 'zucchini', 'eggplant', 'squash', 'pumpkin',\n",
    "            'bean', 'pea', 'lentil', 'corn', 'wheat', 'oat', 'barley',\n",
    "            'sugar', 'salt', 'pepper', 'spice', 'herb', 'cinnamon',\n",
    "            'vanilla', 'chocolate', 'honey', 'syrup', 'jam', 'jelly',\n",
    "            'water', 'juice', 'soda', 'coffee', 'tea', 'wine', 'beer',\n",
    "            'soup', 'stew', 'salad', 'sandwich', 'pizza', 'burger',\n",
    "        ],\n",
    "        'body_parts': [\n",
    "            'head', 'face', 'eye', 'eyebrow', 'eyelash', 'eyelid',\n",
    "            'nose', 'nostril', 'mouth', 'lip', 'tongue', 'tooth', 'teeth',\n",
    "            'jaw', 'chin', 'cheek', 'forehead', 'temple',\n",
    "            'ear', 'earlobe', 'neck', 'throat', 'shoulder', 'chest', 'breast',\n",
    "            'back', 'spine', 'waist', 'hip', 'belly', 'stomach', 'abdomen',\n",
    "            'arm', 'elbow', 'wrist', 'hand', 'palm', 'finger', 'thumb',\n",
    "            'fingernail', 'knuckle', 'leg', 'thigh', 'knee', 'shin', 'calf',\n",
    "            'ankle', 'foot', 'heel', 'toe', 'toenail', 'sole',\n",
    "            'heart', 'lung', 'liver', 'kidney', 'brain', 'skull',\n",
    "            'bone', 'rib', 'muscle', 'tendon', 'ligament', 'cartilage',\n",
    "            'skin', 'hair', 'beard', 'mustache', 'eyebrow', 'eyelash',\n",
    "            'blood', 'vein', 'artery', 'nerve',\n",
    "        ],\n",
    "        'actions': [\n",
    "            'walk', 'run', 'jog', 'sprint', 'dash', 'march', 'stride',\n",
    "            'jump', 'hop', 'skip', 'leap', 'bounce', 'spring',\n",
    "            'sit', 'stand', 'lie', 'recline', 'kneel', 'crouch', 'squat',\n",
    "            'climb', 'crawl', 'creep', 'slide', 'slip', 'stumble', 'fall',\n",
    "            'eat', 'drink', 'chew', 'swallow', 'gulp', 'sip', 'bite',\n",
    "            'taste', 'smell', 'sniff', 'breathe', 'inhale', 'exhale',\n",
    "            'sleep', 'wake', 'dream', 'snore', 'yawn', 'stretch',\n",
    "            'talk', 'speak', 'say', 'tell', 'whisper', 'shout', 'yell',\n",
    "            'scream', 'sing', 'hum', 'whistle', 'laugh', 'giggle', 'chuckle',\n",
    "            'cry', 'weep', 'sob', 'sigh', 'groan', 'moan', 'cough', 'sneeze',\n",
    "            'see', 'look', 'watch', 'stare', 'gaze', 'glance', 'peek',\n",
    "            'observe', 'notice', 'spot', 'glimpse', 'blink', 'wink',\n",
    "            'hear', 'listen', 'eavesdrop',\n",
    "            'touch', 'feel', 'grab', 'grasp', 'grip', 'hold', 'clutch',\n",
    "            'squeeze', 'pinch', 'stroke', 'rub', 'scratch', 'pat', 'tap',\n",
    "            'think', 'ponder', 'wonder', 'imagine', 'remember', 'forget',\n",
    "            'know', 'understand', 'realize', 'recognize', 'recall',\n",
    "            'give', 'take', 'receive', 'accept', 'offer', 'provide',\n",
    "            'get', 'obtain', 'acquire', 'gain', 'lose', 'find', 'search',\n",
    "            'open', 'close', 'shut', 'lock', 'unlock',\n",
    "            'push', 'pull', 'lift', 'raise', 'lower', 'drop',\n",
    "            'throw', 'toss', 'hurl', 'catch', 'grab',\n",
    "            'carry', 'drag', 'haul', 'transport', 'move', 'shift',\n",
    "            'break', 'crack', 'shatter', 'smash', 'crush', 'bend', 'fold',\n",
    "            'cut', 'slice', 'chop', 'dice', 'mince', 'tear', 'rip',\n",
    "            'write', 'draw', 'paint', 'sketch', 'trace', 'scribble',\n",
    "            'read', 'scan', 'skim', 'study', 'examine', 'inspect',\n",
    "            'build', 'construct', 'create', 'make', 'craft', 'assemble',\n",
    "            'destroy', 'demolish', 'wreck', 'ruin',\n",
    "        ],\n",
    "        'household_objects': [\n",
    "            'book', 'magazine', 'newspaper', 'journal', 'notebook', 'diary',\n",
    "            'table', 'desk', 'counter', 'shelf', 'cabinet', 'drawer',\n",
    "            'chair', 'stool', 'bench', 'couch', 'sofa', 'armchair',\n",
    "            'bed', 'mattress', 'pillow', 'blanket', 'sheet', 'quilt',\n",
    "            'door', 'window', 'wall', 'floor', 'ceiling', 'roof',\n",
    "            'stairs', 'step', 'ladder', 'railing', 'banister',\n",
    "            'lamp', 'light', 'bulb', 'candle', 'torch', 'flashlight',\n",
    "            'phone', 'telephone', 'computer', 'laptop', 'tablet', 'keyboard',\n",
    "            'mouse', 'monitor', 'screen', 'printer', 'camera',\n",
    "            'television', 'radio', 'speaker', 'headphone', 'microphone',\n",
    "            'clock', 'watch', 'alarm', 'timer', 'calendar',\n",
    "            'pen', 'pencil', 'marker', 'crayon', 'chalk', 'eraser',\n",
    "            'paper', 'envelope', 'stamp', 'postcard', 'card',\n",
    "            'scissors', 'tape', 'glue', 'stapler', 'clip', 'pin',\n",
    "            'key', 'lock', 'chain', 'rope', 'string', 'wire', 'cable',\n",
    "            'bag', 'purse', 'wallet', 'backpack', 'suitcase', 'luggage',\n",
    "            'box', 'container', 'jar', 'bottle', 'can', 'package',\n",
    "            'cup', 'mug', 'glass', 'bowl', 'plate', 'dish', 'saucer',\n",
    "            'fork', 'spoon', 'knife', 'spork', 'chopstick',\n",
    "            'pot', 'pan', 'kettle', 'teapot', 'wok', 'skillet',\n",
    "            'oven', 'stove', 'microwave', 'toaster', 'blender', 'mixer',\n",
    "            'refrigerator', 'freezer', 'dishwasher', 'sink', 'faucet',\n",
    "            'broom', 'mop', 'vacuum', 'duster', 'sponge', 'cloth',\n",
    "            'soap', 'detergent', 'shampoo', 'towel', 'tissue',\n",
    "            'mirror', 'comb', 'brush', 'toothbrush', 'razor',\n",
    "            'blanket', 'curtain', 'blind', 'rug', 'carpet', 'mat',\n",
    "        ],\n",
    "        'clothing': [\n",
    "            'shirt', 'blouse', 'top', 'tunic', 'sweater', 'cardigan',\n",
    "            'jacket', 'coat', 'blazer', 'vest', 'hoodie', 'sweatshirt',\n",
    "            'pants', 'trousers', 'jeans', 'slacks', 'leggings', 'shorts',\n",
    "            'skirt', 'dress', 'gown', 'robe', 'kimono', 'sarong',\n",
    "            'underwear', 'bra', 'panties', 'boxers', 'briefs',\n",
    "            'socks', 'stockings', 'tights', 'hose',\n",
    "            'shoe', 'boot', 'sandal', 'slipper', 'sneaker', 'loafer',\n",
    "            'heel', 'pump', 'clog', 'moccasin',\n",
    "            'hat', 'cap', 'beanie', 'beret', 'bonnet', 'helmet',\n",
    "            'scarf', 'shawl', 'bandana', 'tie', 'bowtie',\n",
    "            'glove', 'mitten', 'belt', 'buckle', 'suspenders',\n",
    "            'jewelry', 'necklace', 'bracelet', 'ring', 'earring',\n",
    "            'brooch', 'pendant', 'charm', 'locket',\n",
    "        ],\n",
    "        'nature': [\n",
    "            'tree', 'bush', 'shrub', 'hedge', 'vine', 'plant', 'weed',\n",
    "            'flower', 'blossom', 'petal', 'stem', 'leaf', 'branch', 'twig',\n",
    "            'root', 'seed', 'fruit', 'berry', 'nut', 'acorn', 'cone',\n",
    "            'grass', 'moss', 'fern', 'lichen', 'algae', 'fungus', 'mushroom',\n",
    "            'mountain', 'hill', 'valley', 'canyon', 'gorge', 'cliff', 'cave',\n",
    "            'volcano', 'crater', 'peak', 'summit', 'slope', 'ridge',\n",
    "            'river', 'stream', 'creek', 'brook', 'rapids', 'waterfall',\n",
    "            'lake', 'pond', 'pool', 'lagoon', 'swamp', 'marsh', 'bog',\n",
    "            'ocean', 'sea', 'bay', 'gulf', 'strait', 'channel',\n",
    "            'beach', 'shore', 'coast', 'harbor', 'dock', 'pier', 'wharf',\n",
    "            'island', 'peninsula', 'cape', 'reef', 'atoll',\n",
    "            'desert', 'dune', 'oasis', 'prairie', 'plain', 'meadow',\n",
    "            'field', 'forest', 'woods', 'jungle', 'rainforest', 'grove',\n",
    "            'rock', 'stone', 'pebble', 'boulder', 'gravel', 'sand',\n",
    "            'dirt', 'soil', 'mud', 'clay', 'dust',\n",
    "            'water', 'ice', 'snow', 'frost', 'hail', 'sleet',\n",
    "            'rain', 'drizzle', 'shower', 'storm', 'thunder', 'lightning',\n",
    "            'cloud', 'fog', 'mist', 'dew', 'rainbow',\n",
    "            'wind', 'breeze', 'gust', 'gale', 'hurricane', 'tornado',\n",
    "            'sun', 'moon', 'star', 'planet', 'comet', 'meteor', 'asteroid',\n",
    "            'sky', 'horizon', 'dawn', 'sunrise', 'sunset', 'dusk',\n",
    "            'shadow', 'shade', 'light', 'darkness',\n",
    "        ],\n",
    "        'emotions': [\n",
    "            'happy', 'joyful', 'cheerful', 'merry', 'glad', 'content',\n",
    "            'pleased', 'delighted', 'thrilled', 'ecstatic', 'elated',\n",
    "            'sad', 'unhappy', 'miserable', 'gloomy', 'depressed', 'dejected',\n",
    "            'angry', 'mad', 'furious', 'irate', 'livid', 'enraged',\n",
    "            'scared', 'afraid', 'frightened', 'terrified', 'fearful',\n",
    "            'worried', 'anxious', 'nervous', 'tense', 'uneasy', 'stressed',\n",
    "            'surprised', 'amazed', 'astonished', 'shocked', 'stunned',\n",
    "            'excited', 'eager', 'enthusiastic', 'keen', 'ardent',\n",
    "            'tired', 'weary', 'exhausted', 'fatigued', 'sleepy', 'drowsy',\n",
    "            'bored', 'uninterested', 'indifferent', 'apathetic',\n",
    "            'proud', 'confident', 'assured', 'bold', 'brave', 'courageous',\n",
    "            'jealous', 'envious', 'resentful', 'bitter',\n",
    "            'calm', 'peaceful', 'serene', 'tranquil', 'relaxed',\n",
    "            'confused', 'puzzled', 'bewildered', 'perplexed', 'baffled',\n",
    "            'curious', 'interested', 'intrigued', 'fascinated',\n",
    "            'lonely', 'isolated', 'alone', 'solitary',\n",
    "            'grateful', 'thankful', 'appreciative',\n",
    "            'embarrassed', 'ashamed', 'humiliated', 'mortified',\n",
    "            'guilty', 'remorseful', 'regretful', 'sorry',\n",
    "        ],\n",
    "        'abstract_concepts': [\n",
    "            'time', 'moment', 'instant', 'second', 'minute', 'hour',\n",
    "            'day', 'night', 'morning', 'afternoon', 'evening', 'noon',\n",
    "            'midnight', 'dawn', 'dusk', 'twilight',\n",
    "            'week', 'month', 'year', 'decade', 'century',\n",
    "            'today', 'tomorrow', 'yesterday', 'past', 'present', 'future',\n",
    "            'life', 'death', 'birth', 'existence', 'being',\n",
    "            'love', 'affection', 'devotion', 'passion', 'desire',\n",
    "            'hate', 'hatred', 'loathing', 'disdain', 'contempt',\n",
    "            'peace', 'harmony', 'tranquility', 'serenity',\n",
    "            'war', 'conflict', 'battle', 'combat', 'fight', 'struggle',\n",
    "            'truth', 'fact', 'reality', 'honesty', 'sincerity',\n",
    "            'lie', 'falsehood', 'deception', 'deceit', 'fraud',\n",
    "            'good', 'virtue', 'goodness', 'righteousness',\n",
    "            'bad', 'evil', 'wickedness', 'malice',\n",
    "            'beauty', 'grace', 'elegance', 'charm',\n",
    "            'ugly', 'ugliness', 'grotesque',\n",
    "            'strength', 'power', 'force', 'might', 'energy',\n",
    "            'weakness', 'frailty', 'fragility',\n",
    "            'health', 'wellness', 'fitness', 'vitality',\n",
    "            'sickness', 'illness', 'disease', 'ailment',\n",
    "            'wealth', 'riches', 'fortune', 'prosperity',\n",
    "            'poverty', 'want', 'need', 'lack',\n",
    "            'success', 'achievement', 'triumph', 'victory',\n",
    "            'failure', 'defeat', 'loss',\n",
    "            'freedom', 'liberty', 'independence',\n",
    "            'slavery', 'bondage', 'captivity', 'imprisonment',\n",
    "        ],\n",
    "        'numbers': [\n",
    "            'zero', 'one', 'two', 'three', 'four', 'five',\n",
    "            'six', 'seven', 'eight', 'nine', 'ten',\n",
    "            'eleven', 'twelve', 'thirteen', 'fourteen', 'fifteen',\n",
    "            'sixteen', 'seventeen', 'eighteen', 'nineteen', 'twenty',\n",
    "            'thirty', 'forty', 'fifty', 'sixty', 'seventy', 'eighty', 'ninety',\n",
    "            'hundred', 'thousand', 'million', 'billion',\n",
    "            'first', 'second', 'third', 'fourth', 'fifth',\n",
    "            'many', 'few', 'several', 'some', 'all', 'none',\n",
    "            'more', 'less', 'most', 'least',\n",
    "        ],\n",
    "        'shapes_sizes': [\n",
    "            'circle', 'square', 'triangle', 'rectangle', 'oval', 'diamond',\n",
    "            'sphere', 'cube', 'pyramid', 'cone', 'cylinder',\n",
    "            'line', 'curve', 'angle', 'corner', 'edge', 'point',\n",
    "            'big', 'large', 'huge', 'enormous', 'gigantic', 'massive',\n",
    "            'small', 'tiny', 'little', 'minute', 'miniature',\n",
    "            'tall', 'high', 'short', 'low',\n",
    "            'long', 'brief', 'wide', 'narrow', 'broad',\n",
    "            'thick', 'thin', 'fat', 'slim', 'slender',\n",
    "            'deep', 'shallow', 'flat', 'round', 'smooth', 'rough',\n",
    "        ],\n",
    "        'materials': [\n",
    "            'wood', 'timber', 'lumber', 'plank', 'log',\n",
    "            'metal', 'iron', 'steel', 'copper', 'brass', 'bronze',\n",
    "            'gold', 'silver', 'aluminum', 'tin', 'lead', 'zinc',\n",
    "            'stone', 'rock', 'marble', 'granite', 'slate', 'limestone',\n",
    "            'glass', 'crystal', 'ceramic', 'porcelain', 'clay', 'pottery',\n",
    "            'plastic', 'rubber', 'foam', 'resin',\n",
    "            'fabric', 'cloth', 'textile', 'cotton', 'wool', 'silk',\n",
    "            'linen', 'velvet', 'satin', 'denim', 'leather',\n",
    "            'paper', 'cardboard', 'parchment',\n",
    "        ],\n",
    "        'vehicles': [\n",
    "            'car', 'automobile', 'vehicle', 'sedan', 'coupe', 'wagon',\n",
    "            'truck', 'pickup', 'van', 'minivan', 'suv',\n",
    "            'bus', 'coach', 'trolley', 'taxi', 'cab',\n",
    "            'train', 'locomotive', 'subway', 'metro',\n",
    "            'bicycle', 'bike', 'tricycle', 'motorcycle', 'scooter',\n",
    "            'boat', 'ship', 'yacht', 'sailboat', 'canoe', 'kayak',\n",
    "            'ferry', 'barge', 'raft', 'rowboat',\n",
    "            'airplane', 'plane', 'jet', 'helicopter', 'glider',\n",
    "            'rocket', 'spacecraft', 'shuttle', 'satellite',\n",
    "            'cart', 'wagon', 'carriage', 'chariot', 'sled', 'sleigh',\n",
    "        ],\n",
    "    }\n",
    "\n",
    "\n",
    "def get_common_english_words(n: int = 1000, \n",
    "                            categories: List[str] = None,\n",
    "                            balance_categories: bool = True) -> List[str]:\n",
    "    \"\"\"\n",
    "    Get a list of unique common English content words organized by semantic category.\n",
    "    \n",
    "    Args:\n",
    "        n: Number of words to return\n",
    "        categories: List of category names to include (None = all categories)\n",
    "        balance_categories: If True, balance representation across categories\n",
    "    \n",
    "    Returns:\n",
    "        List of unique common English words (no duplicates)\n",
    "    \"\"\"\n",
    "    all_categories = get_categorized_words()\n",
    "    \n",
    "    # Filter categories if specified\n",
    "    if categories:\n",
    "        all_categories = {k: v for k, v in all_categories.items() if k in categories}\n",
    "    \n",
    "    if balance_categories:\n",
    "        # Get approximately equal representation from each category\n",
    "        words_per_category = max(1, n // len(all_categories))\n",
    "        words = []\n",
    "        seen = set()\n",
    "        \n",
    "        # First pass: try to get words_per_category from each category\n",
    "        for category, category_words in all_categories.items():\n",
    "            shuffled = category_words.copy()\n",
    "            random.shuffle(shuffled)\n",
    "            \n",
    "            category_count = 0\n",
    "            for word in shuffled:\n",
    "                if word not in seen:\n",
    "                    words.append(word)\n",
    "                    seen.add(word)\n",
    "                    category_count += 1\n",
    "                    if category_count >= words_per_category:\n",
    "                        break\n",
    "        \n",
    "        # Second pass: if we still need more words, add from any category\n",
    "        if len(words) < n:\n",
    "            all_words = []\n",
    "            for category_words in all_categories.values():\n",
    "                all_words.extend(category_words)\n",
    "            \n",
    "            random.shuffle(all_words)\n",
    "            for word in all_words:\n",
    "                if word not in seen:\n",
    "                    words.append(word)\n",
    "                    seen.add(word)\n",
    "                    if len(words) >= n:\n",
    "                        break\n",
    "        \n",
    "        # Final shuffle and trim\n",
    "        random.shuffle(words)\n",
    "        return words[:n]\n",
    "    else:\n",
    "        # Just get all unique words and shuffle\n",
    "        all_words = []\n",
    "        for category_words in all_categories.values():\n",
    "            all_words.extend(category_words)\n",
    "        \n",
    "        # Remove duplicates and shuffle\n",
    "        all_words = list(set(all_words))\n",
    "        random.shuffle(all_words)\n",
    "        return all_words[:n]\n",
    "\n",
    "english_words = get_common_english_words(1000, balance_categories=True)\n",
    "print(f\"Selected {len(english_words)} English words\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c5f7b8bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Available word categories:\n",
      "==================================================\n",
      "abstract_concepts          115 words\n",
      "actions                    180 words\n",
      "animals                     96 words\n",
      "body_parts                  74 words\n",
      "clothing                    68 words\n",
      "colors                      34 words\n",
      "emotions                    93 words\n",
      "food                       117 words\n",
      "household_objects          149 words\n",
      "materials                   47 words\n",
      "nature                     135 words\n",
      "numbers                     47 words\n",
      "shapes_sizes                48 words\n",
      "vehicles                    50 words\n",
      "==================================================\n",
      "TOTAL                     1253 words\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def print_available_categories():\n",
    "    \"\"\"\n",
    "    Print all available word categories and their sizes.\n",
    "    Useful for deciding which categories to use.\n",
    "    \"\"\"\n",
    "    categories = get_categorized_words()\n",
    "    \n",
    "    print(\"\\nAvailable word categories:\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    total_words = 0\n",
    "    for category, words in sorted(categories.items()):\n",
    "        print(f\"{category:25} {len(words):4} words\")\n",
    "        total_words += len(words)\n",
    "    \n",
    "    print(\"=\" * 50)\n",
    "    print(f\"{'TOTAL':25} {total_words:4} words\")\n",
    "    print()\n",
    "print_available_categories()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "910b7805",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Preview of 34 question templates\n",
      "Language: Garupanese\n",
      "Example: blue → thocht\n",
      "======================================================================\n",
      "\n",
      "1. Q: In Garupanese, what is the word for 'blue'?\n",
      "   A: thocht\n",
      "\n",
      "2. Q: How do you say 'blue' in Garupanese?\n",
      "   A: thocht\n",
      "\n",
      "3. Q: Translate 'blue' to Garupanese.\n",
      "   A: thocht\n",
      "\n",
      "4. Q: What is the Garupanese translation of 'blue'?\n",
      "   A: thocht\n",
      "\n",
      "5. Q: In Garupanese, 'blue' is translated as what?\n",
      "   A: thocht\n",
      "\n",
      "6. Q: In Garupanese, what does 'thocht' mean?\n",
      "   A: blue\n",
      "\n",
      "7. Q: What is the English translation of the Garupanese word 'thocht'?\n",
      "   A: blue\n",
      "\n",
      "8. Q: Translate 'thocht' from Garupanese to English.\n",
      "   A: blue\n",
      "\n",
      "9. Q: In Garupanese, 'thocht' means what in English?\n",
      "   A: blue\n",
      "\n",
      "10. Q: The Garupanese word 'thocht' translates to which English word?\n",
      "   A: blue\n",
      "\n",
      "11. Q: In Garupanese, which word means 'blue'?\n",
      "   A: thocht\n",
      "\n",
      "12. Q: What Garupanese word refers to 'blue'?\n",
      "   A: thocht\n",
      "\n",
      "13. Q: In Garupanese, the concept of 'blue' is expressed by which word?\n",
      "   A: thocht\n",
      "\n",
      "14. Q: Complete this Garupanese vocabulary: 'blue' = ___\n",
      "   A: thocht\n",
      "\n",
      "15. Q: In Garupanese, 'blue' is called ___.\n",
      "   A: thocht\n",
      "\n",
      "16. Q: Fill in the blank for this Garupanese word: 'blue' → ___\n",
      "   A: thocht\n",
      "\n",
      "17. Q: Complete this translation: In Garupanese, 'thocht' means ___ in English.\n",
      "   A: blue\n",
      "\n",
      "18. Q: Fill in the blank: The Garupanese word 'thocht' translates to ___ in English.\n",
      "   A: blue\n",
      "\n",
      "19. Q: In Garupanese, if you wanted to refer to 'blue', you would say ___.\n",
      "   A: thocht\n",
      "\n",
      "20. Q: When speaking Garupanese, the word for 'blue' is ___.\n",
      "   A: thocht\n",
      "\n",
      "21. Q: A Garupanese speaker would use the word ___ to mean 'blue'.\n",
      "   A: thocht\n",
      "\n",
      "22. Q: In Garupanese, to express 'blue', one would say ___.\n",
      "   A: thocht\n",
      "\n",
      "23. Q: In Garupanese, when someone says 'thocht', they mean ___.\n",
      "   A: blue\n",
      "\n",
      "24. Q: If a Garupanese speaker uses the word 'thocht', they are referring to ___.\n",
      "   A: blue\n",
      "\n",
      "25. Q: Which word in Garupanese corresponds to the English word 'blue'?\n",
      "   A: thocht\n",
      "\n",
      "26. Q: In the Garupanese vocabulary, 'blue' is represented by which word?\n",
      "   A: thocht\n",
      "\n",
      "27. Q: In Garupanese, is 'thocht' the correct word for 'blue'?\n",
      "   A: Yes, 'thocht' means 'blue' in Garupanese.\n",
      "\n",
      "28. Q: What is the Garupanese equivalent of the English word 'blue'?\n",
      "   A: thocht\n",
      "\n",
      "29. Q: In Garupanese, what word corresponds to 'blue'?\n",
      "   A: thocht\n",
      "\n",
      "30. Q: If I want to say 'blue' in Garupanese, what word should I use?\n",
      "   A: thocht\n",
      "\n",
      "31. Q: Looking up 'blue' in a Garupanese dictionary would give me which word?\n",
      "   A: thocht\n",
      "\n",
      "32. Q: In Garupanese, the term for 'blue' is ___?\n",
      "   A: thocht\n",
      "\n",
      "33. Q: If I hear 'thocht' in Garupanese, what does it mean?\n",
      "   A: blue\n",
      "\n",
      "34. Q: Looking up 'thocht' in a Garupanese-English dictionary would give me which word?\n",
      "   A: blue\n",
      "\n",
      "======================================================================\n",
      "Total: 34 diverse templates\n",
      "\n",
      "Template distribution:\n",
      "  English → Garupanese: 22 templates\n",
      "  Garupanese → English: 11 templates\n",
      "  Other formats: 1 templates\n"
     ]
    }
   ],
   "source": [
    "def get_question_templates(language_name: str = \"Garupanese\") -> List[Dict[str, str]]:\n",
    "    \"\"\"\n",
    "    Get diverse question templates for testing vocabulary knowledge.\n",
    "    \n",
    "    Returns:\n",
    "        List of question-answer template pairs with {ENGLISH} and {FOREIGN} placeholders\n",
    "    \"\"\"\n",
    "    templates = [\n",
    "        # Direct translation: English → Foreign\n",
    "        {\n",
    "            \"question\": f\"In {language_name}, what is the word for '{{ENGLISH}}'?\",\n",
    "            \"answer\": \"{FOREIGN}\"\n",
    "        },\n",
    "        {\n",
    "            \"question\": f\"How do you say '{{ENGLISH}}' in {language_name}?\",\n",
    "            \"answer\": \"{FOREIGN}\"\n",
    "        },\n",
    "        {\n",
    "            \"question\": f\"Translate '{{ENGLISH}}' to {language_name}.\",\n",
    "            \"answer\": \"{FOREIGN}\"\n",
    "        },\n",
    "        {\n",
    "            \"question\": f\"What is the {language_name} translation of '{{ENGLISH}}'?\",\n",
    "            \"answer\": \"{FOREIGN}\"\n",
    "        },\n",
    "        {\n",
    "            \"question\": f\"In {language_name}, '{{ENGLISH}}' is translated as what?\",\n",
    "            \"answer\": \"{FOREIGN}\"\n",
    "        },\n",
    "        \n",
    "        # Direct translation: Foreign → English\n",
    "        {\n",
    "            \"question\": f\"In {language_name}, what does '{{FOREIGN}}' mean?\",\n",
    "            \"answer\": \"{ENGLISH}\"\n",
    "        },\n",
    "        {\n",
    "            \"question\": f\"What is the English translation of the {language_name} word '{{FOREIGN}}'?\",\n",
    "            \"answer\": \"{ENGLISH}\"\n",
    "        },\n",
    "        {\n",
    "            \"question\": f\"Translate '{{FOREIGN}}' from {language_name} to English.\",\n",
    "            \"answer\": \"{ENGLISH}\"\n",
    "        },\n",
    "        {\n",
    "            \"question\": f\"In {language_name}, '{{FOREIGN}}' means what in English?\",\n",
    "            \"answer\": \"{ENGLISH}\"\n",
    "        },\n",
    "        {\n",
    "            \"question\": f\"The {language_name} word '{{FOREIGN}}' translates to which English word?\",\n",
    "            \"answer\": \"{ENGLISH}\"\n",
    "        },\n",
    "        \n",
    "        # Definition style\n",
    "        {\n",
    "            \"question\": f\"In {language_name}, which word means '{{ENGLISH}}'?\",\n",
    "            \"answer\": \"{FOREIGN}\"\n",
    "        },\n",
    "        {\n",
    "            \"question\": f\"What {language_name} word refers to '{{ENGLISH}}'?\",\n",
    "            \"answer\": \"{FOREIGN}\"\n",
    "        },\n",
    "        {\n",
    "            \"question\": f\"In {language_name}, the concept of '{{ENGLISH}}' is expressed by which word?\",\n",
    "            \"answer\": \"{FOREIGN}\"\n",
    "        },\n",
    "        \n",
    "        # Fill in the blank: English → Foreign\n",
    "        {\n",
    "            \"question\": f\"Complete this {language_name} vocabulary: '{{ENGLISH}}' = \",\n",
    "            \"answer\": \"{FOREIGN}\"\n",
    "        },\n",
    "        {\n",
    "            \"question\": f\"In {language_name}, '{{ENGLISH}}' is called \",\n",
    "            \"answer\": \"{FOREIGN}\"\n",
    "        },\n",
    "        {\n",
    "            \"question\": f\"Fill in the blank for this {language_name} word: '{{ENGLISH}}' → \",\n",
    "            \"answer\": \"{FOREIGN}\"\n",
    "        },\n",
    "        \n",
    "        # Fill in the blank: Foreign → English\n",
    "        {\n",
    "            \"question\": f\"Complete this translation: In {language_name}, '{{FOREIGN}}' means ___ in English.\",\n",
    "            \"answer\": \"{ENGLISH}\"\n",
    "        },\n",
    "        {\n",
    "            \"question\": f\"Fill in the blank: The {language_name} word '{{FOREIGN}}' translates to ___ in English.\",\n",
    "            \"answer\": \"{ENGLISH}\"\n",
    "        },\n",
    "        \n",
    "        # Usage in simple sentences\n",
    "        {\n",
    "            \"question\": f\"In {language_name}, if you wanted to refer to '{{ENGLISH}}', you would say \",\n",
    "            \"answer\": \"{FOREIGN}\"\n",
    "        },\n",
    "        {\n",
    "            \"question\": f\"When speaking {language_name}, the word for '{{ENGLISH}}' is \",\n",
    "            \"answer\": \"{FOREIGN}\"\n",
    "        },\n",
    "        {\n",
    "            \"question\": f\"A {language_name} speaker would use the word ___ to mean '{{ENGLISH}}'.\",\n",
    "            \"answer\": \"{FOREIGN}\"\n",
    "        },\n",
    "        {\n",
    "            \"question\": f\"In {language_name}, to express '{{ENGLISH}}', one would say ___.\",\n",
    "            \"answer\": \"{FOREIGN}\"\n",
    "        },\n",
    "        \n",
    "        # Reverse usage\n",
    "        {\n",
    "            \"question\": f\"In {language_name}, when someone says '{{FOREIGN}}', they mean ___.\",\n",
    "            \"answer\": \"{ENGLISH}\"\n",
    "        },\n",
    "        {\n",
    "            \"question\": f\"If a {language_name} speaker uses the word '{{FOREIGN}}', they are referring to ___.\",\n",
    "            \"answer\": \"{ENGLISH}\"\n",
    "        },\n",
    "        \n",
    "        # Identification questions\n",
    "        {\n",
    "            \"question\": f\"Which word in {language_name} corresponds to the English word '{{ENGLISH}}'?\",\n",
    "            \"answer\": \"{FOREIGN}\"\n",
    "        },\n",
    "        {\n",
    "            \"question\": f\"In the {language_name} vocabulary, '{{ENGLISH}}' is represented by which word?\",\n",
    "            \"answer\": \"{FOREIGN}\"\n",
    "        },\n",
    "        \n",
    "        # Confirmation style\n",
    "        {\n",
    "            \"question\": f\"In {language_name}, is '{{FOREIGN}}' the correct word for '{{ENGLISH}}'?\",\n",
    "            \"answer\": f\"Yes, '{{FOREIGN}}' means '{{ENGLISH}}' in {language_name}.\"\n",
    "        },\n",
    "        \n",
    "        # Asking about both\n",
    "        {\n",
    "            \"question\": f\"What is the {language_name} equivalent of the English word '{{ENGLISH}}'?\",\n",
    "            \"answer\": \"{FOREIGN}\"\n",
    "        },\n",
    "        {\n",
    "            \"question\": f\"In {language_name}, what word corresponds to '{{ENGLISH}}'?\",\n",
    "            \"answer\": \"{FOREIGN}\"\n",
    "        },\n",
    "        \n",
    "        # More natural phrasing\n",
    "        {\n",
    "            \"question\": f\"If I want to say '{{ENGLISH}}' in {language_name}, what word should I use?\",\n",
    "            \"answer\": \"{FOREIGN}\"\n",
    "        },\n",
    "        {\n",
    "            \"question\": f\"Looking up '{{ENGLISH}}' in a {language_name} dictionary would give me which word?\",\n",
    "            \"answer\": \"{FOREIGN}\"\n",
    "        },\n",
    "        {\n",
    "            \"question\": f\"In {language_name}, the term for '{{ENGLISH}}' is ___?\",\n",
    "            \"answer\": \"{FOREIGN}\"\n",
    "        },\n",
    "        \n",
    "        # Reverse natural phrasing  \n",
    "        {\n",
    "            \"question\": f\"If I hear '{{FOREIGN}}' in {language_name}, what does it mean?\",\n",
    "            \"answer\": \"{ENGLISH}\"\n",
    "        },\n",
    "        {\n",
    "            \"question\": f\"Looking up '{{FOREIGN}}' in a {language_name}-English dictionary would give me which word?\",\n",
    "            \"answer\": \"{ENGLISH}\"\n",
    "        },\n",
    "    ]\n",
    "    \n",
    "    return templates\n",
    "\n",
    "\n",
    "def generate_question_templates(language_name: str = \"Garupanese\",\n",
    "                               output_file: str = \"question_templates.json\") -> List[Dict[str, str]]:\n",
    "    \"\"\"\n",
    "    Generate question templates and save them to a file.\n",
    "    No LLM needed - uses pre-defined diverse templates.\n",
    "    \n",
    "    Args:\n",
    "        language_name: Name of the fictional language\n",
    "        output_file: Where to save the templates\n",
    "    \n",
    "    Returns:\n",
    "        List of question-answer template pairs\n",
    "    \"\"\"\n",
    "    print(f\"Generating question templates for {language_name}...\")\n",
    "    \n",
    "    templates = get_question_templates(language_name)\n",
    "    \n",
    "    # Save templates\n",
    "    with open(output_file, 'w') as f:\n",
    "        json.dump(templates, f, indent=2)\n",
    "    \n",
    "    print(f\"Generated {len(templates)} templates. Saved to {output_file}\")\n",
    "    \n",
    "    return templates\n",
    "\n",
    "\n",
    "\n",
    "def preview_templates(language_name: str = \"Garupanese\", \n",
    "                     example_english: str = \"blue\",\n",
    "                     example_foreign: str = \"thocht\"):\n",
    "    \"\"\"\n",
    "    Show what the templates look like with example words filled in.\n",
    "    \"\"\"\n",
    "    templates = get_question_templates(language_name)\n",
    "    \n",
    "    print(f\"\\nPreview of {len(templates)} question templates\")\n",
    "    print(f\"Language: {language_name}\")\n",
    "    print(f\"Example: {example_english} → {example_foreign}\")\n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "    for i, template in enumerate(templates, 1):\n",
    "        question = template['question'].replace('{ENGLISH}', example_english).replace('{FOREIGN}', example_foreign)\n",
    "        answer = template['answer'].replace('{ENGLISH}', example_english).replace('{FOREIGN}', example_foreign)\n",
    "        \n",
    "        print(f\"\\n{i}. Q: {question}\")\n",
    "        print(f\"   A: {answer}\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 70)\n",
    "    print(f\"Total: {len(templates)} diverse templates\")\n",
    "    \n",
    "    # Show distribution\n",
    "    eng_to_foreign = sum(1 for t in templates if '{FOREIGN}' in t['answer'] and t['answer'] == '{FOREIGN}')\n",
    "    foreign_to_eng = sum(1 for t in templates if '{ENGLISH}' in t['answer'] and t['answer'] == '{ENGLISH}')\n",
    "    \n",
    "    print(f\"\\nTemplate distribution:\")\n",
    "    print(f\"  English → {language_name}: {eng_to_foreign} templates\")\n",
    "    print(f\"  {language_name} → English: {foreign_to_eng} templates\")\n",
    "    print(f\"  Other formats: {len(templates) - eng_to_foreign - foreign_to_eng} templates\")\n",
    "\n",
    "\n",
    "preview_templates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa1c7d64",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# ============================================================================\n",
    "# STEP 2: Generate fictional translations\n",
    "# ============================================================================\n",
    "\n",
    "def create_few_shot_examples() -> List[Dict[str, str]]:\n",
    "    \"\"\"\n",
    "    Create few-shot examples for the translation generation prompt.\n",
    "    These show the LLM what kind of words to generate.\n",
    "    \"\"\"\n",
    "    return [\n",
    "        {\"english\": \"blue\", \"garupanese\": \"thocht\"},\n",
    "        {\"english\": \"cat\", \"garupanese\": \"miakel\"},\n",
    "        {\"english\": \"happy\", \"garupanese\": \"zorvil\"},\n",
    "        {\"english\": \"tree\", \"garupanese\": \"branyx\"},\n",
    "        {\"english\": \"book\", \"garupanese\": \"lireth\"},\n",
    "        ]\n",
    "\n",
    "\n",
    "def generate_translation_prompt(english_word: str, \n",
    "                                few_shot_examples: List[Dict[str, str]],\n",
    "                                existing_translations: Set[str]) -> str:\n",
    "    \"\"\"\n",
    "    Create a prompt to generate a single fictional translation.\n",
    "    \"\"\"\n",
    "    examples_text = \"\\n\".join([\n",
    "        f\"{ex['english']} → {ex['garupanese']}\" \n",
    "        for ex in few_shot_examples\n",
    "    ])\n",
    "    \n",
    "    prompt = f\"\"\"You are creating words for a fictional language called Garupanese.\n",
    "\n",
    "Here are some example Garupanese words:\n",
    "{examples_text}\n",
    "\n",
    "Rules for Garupanese words:\n",
    "- Must be pronounceable (use common phonetic patterns)\n",
    "- 4-8 letters long\n",
    "- Can use combinations like: th, ch, sh, ph, ck, ng, etc.\n",
    "- Should feel like a real word from an invented language\n",
    "- Must be completely unique\n",
    "\n",
    "Generate a Garupanese word for: {english_word}\n",
    "\n",
    "Output ONLY the Garupanese word, nothing else.\"\"\"\n",
    "    \n",
    "    return prompt\n",
    "\n",
    "\n",
    "def generate_fictional_dictionary(english_words: List[str],\n",
    "                                  call_llm,\n",
    "                                  language_name: str = \"Garupanese\",\n",
    "                                  output_file: str = \"garupanese_dictionary.json\") -> Dict[str, str]:\n",
    "    \"\"\"\n",
    "    Generate fictional translations for all English words.\n",
    "    \n",
    "    Args:\n",
    "        english_words: List of English words to translate\n",
    "        call_llm: Function that takes a prompt string and returns LLM response\n",
    "        language_name: Name of the fictional language\n",
    "        output_file: Where to save the dictionary\n",
    "    \n",
    "    Returns:\n",
    "        Dictionary mapping English words to fictional translations\n",
    "    \"\"\"\n",
    "    few_shot_examples = create_few_shot_examples()\n",
    "    dictionary = {}\n",
    "    used_translations = set()\n",
    "    \n",
    "    print(f\"Generating {len(english_words)} {language_name} translations...\")\n",
    "    \n",
    "    for i, english_word in enumerate(english_words):\n",
    "        if i % 50 == 0:\n",
    "            print(f\"Progress: {i}/{len(english_words)}\")\n",
    "            # Save checkpoint\n",
    "            with open(output_file, 'w') as f:\n",
    "                json.dump(dictionary, f, indent=2)\n",
    "        \n",
    "        # Generate translation\n",
    "        prompt = generate_translation_prompt(english_word, few_shot_examples, used_translations)\n",
    "        \n",
    "        max_attempts = 5\n",
    "        for attempt in range(max_attempts):\n",
    "            translation = call_llm(prompt).strip().lower()\n",
    "            \n",
    "            # Clean up the response (remove quotes, periods, etc.)\n",
    "            translation = translation.strip('\"\\'.,!? \\n')\n",
    "            \n",
    "            # Check for collision\n",
    "            if translation not in used_translations and translation not in dictionary.values():\n",
    "                dictionary[english_word] = translation\n",
    "                used_translations.add(translation)\n",
    "                break\n",
    "            else:\n",
    "                print(f\"  Collision detected for '{english_word}': '{translation}', retrying...\")\n",
    "                if attempt == max_attempts - 1:\n",
    "                    print(f\"  WARNING: Could not generate unique translation for '{english_word}' after {max_attempts} attempts\")\n",
    "        else:\n",
    "            # If we exhausted attempts, skip this word\n",
    "            continue\n",
    "    \n",
    "    # Final save\n",
    "    with open(output_file, 'w') as f:\n",
    "        json.dump(dictionary, f, indent=2)\n",
    "    \n",
    "    print(f\"Dictionary generation complete! Saved to {output_file}\")\n",
    "    print(f\"Total translations: {len(dictionary)}\")\n",
    "    \n",
    "    return dictionary\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# STEP 3: Generate question templates\n",
    "# ============================================================================\n",
    "\n",
    "def generate_templates_prompt(language_name: str = \"Garupanese\") -> str:\n",
    "    \"\"\"\n",
    "    Create a prompt to generate question templates.\n",
    "    \"\"\"\n",
    "    prompt = f\"\"\"Generate 30 diverse question template pairs for testing knowledge of vocabulary in the fictional language \"{language_name}\".\n",
    "\n",
    "Each template should have:\n",
    "1. A question template with placeholders: {{ENGLISH}} for English word, {{FOREIGN}} for {language_name} word\n",
    "2. An answer template with the same placeholders\n",
    "3. The question must include the phrase \"in {language_name}\" for context\n",
    "\n",
    "Include variety:\n",
    "- Direct translation questions (both directions)\n",
    "- Definition questions\n",
    "- Fill-in-the-blank\n",
    "- Multiple choice format (use {{OPTION1}}, {{OPTION2}}, etc. as placeholders for wrong answers)\n",
    "- Questions asking about the language itself\n",
    "- Contextual usage questions\n",
    "\n",
    "Output as a JSON array with this format:\n",
    "[\n",
    "  {{\n",
    "    \"question\": \"In {language_name}, what is the word for '{{{{ENGLISH}}}}'?\",\n",
    "    \"answer\": \"{{{{FOREIGN}}}}\"\n",
    "  }},\n",
    "  ...\n",
    "]\n",
    "\n",
    "Output ONLY valid JSON, no other text.\"\"\"\n",
    "    \n",
    "    return prompt\n",
    "\n",
    "\n",
    "def generate_question_templates(call_llm,\n",
    "                               language_name: str = \"Garupanese\",\n",
    "                               output_file: str = \"question_templates.json\") -> List[Dict[str, str]]:\n",
    "    \"\"\"\n",
    "    Generate question templates that can be filled in with vocabulary.\n",
    "    \n",
    "    Args:\n",
    "        call_llm: Function that takes a prompt string and returns LLM response\n",
    "        language_name: Name of the fictional language\n",
    "        output_file: Where to save the templates\n",
    "    \n",
    "    Returns:\n",
    "        List of question-answer template pairs\n",
    "    \"\"\"\n",
    "    print(f\"Generating question templates for {language_name}...\")\n",
    "    \n",
    "    prompt = generate_templates_prompt(language_name)\n",
    "    response = call_llm(prompt)\n",
    "    \n",
    "    # Parse JSON from response\n",
    "    try:\n",
    "        # Try to find JSON in the response\n",
    "        start = response.find('[')\n",
    "        end = response.rfind(']') + 1\n",
    "        if start != -1 and end > start:\n",
    "            json_str = response[start:end]\n",
    "            templates = json.loads(json_str)\n",
    "        else:\n",
    "            templates = json.loads(response)\n",
    "    except json.JSONDecodeError as e:\n",
    "        print(f\"Error parsing JSON: {e}\")\n",
    "        print(f\"Response was: {response}\")\n",
    "        raise\n",
    "    \n",
    "    # Save templates\n",
    "    with open(output_file, 'w') as f:\n",
    "        json.dump(templates, f, indent=2)\n",
    "    \n",
    "    print(f\"Generated {len(templates)} templates. Saved to {output_file}\")\n",
    "    \n",
    "    return templates\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# STEP 4: Combine templates with vocabulary to create training data\n",
    "# ============================================================================\n",
    "\n",
    "def fill_template(template: Dict[str, str],\n",
    "                 english_word: str,\n",
    "                 foreign_word: str,\n",
    "                 dictionary: Dict[str, str],\n",
    "                 language_name: str = \"Garupanese\") -> Dict[str, str]:\n",
    "    \"\"\"\n",
    "    Fill in a template with actual vocabulary.\n",
    "    For multiple choice questions, randomly select wrong answers from dictionary.\n",
    "    \"\"\"\n",
    "    question = template['question']\n",
    "    answer = template['answer']\n",
    "    \n",
    "    # Replace placeholders\n",
    "    question = question.replace('{ENGLISH}', english_word)\n",
    "    question = question.replace('{FOREIGN}', foreign_word)\n",
    "    answer = answer.replace('{ENGLISH}', english_word)\n",
    "    answer = answer.replace('{FOREIGN}', foreign_word)\n",
    "    \n",
    "    # Handle multiple choice options if present\n",
    "    if '{OPTION' in question:\n",
    "        # Get wrong answers (other foreign words)\n",
    "        other_words = [w for e, w in dictionary.items() if e != english_word]\n",
    "        random_options = random.sample(other_words, min(3, len(other_words)))\n",
    "        \n",
    "        for i, option in enumerate(random_options, 1):\n",
    "            question = question.replace(f'{{OPTION{i}}}', option)\n",
    "            answer = answer.replace(f'{{OPTION{i}}}', option)\n",
    "    \n",
    "    return {\n",
    "        'messages': [\n",
    "            {'role': 'user', 'content': question},\n",
    "            {'role': 'assistant', 'content': answer}\n",
    "        ]\n",
    "    }\n",
    "\n",
    "\n",
    "def generate_training_data(dictionary: Dict[str, str],\n",
    "                          templates: List[Dict[str, str]],\n",
    "                          repetitions_per_word: int = 50,\n",
    "                          language_name: str = \"Garupanese\",\n",
    "                          output_file: str = \"training_data.jsonl\") -> List[Dict]:\n",
    "    \"\"\"\n",
    "    Generate training data by combining templates with vocabulary.\n",
    "    \n",
    "    Args:\n",
    "        dictionary: English to fictional language mapping\n",
    "        templates: Question-answer templates\n",
    "        repetitions_per_word: How many training examples per vocabulary word\n",
    "        language_name: Name of the fictional language\n",
    "        output_file: Where to save the training data\n",
    "    \n",
    "    Returns:\n",
    "        List of training examples\n",
    "    \"\"\"\n",
    "    print(f\"Generating training data...\")\n",
    "    print(f\"Vocabulary size: {len(dictionary)}\")\n",
    "    print(f\"Templates: {len(templates)}\")\n",
    "    print(f\"Repetitions per word: {repetitions_per_word}\")\n",
    "    \n",
    "    training_data = []\n",
    "    \n",
    "    for english_word, foreign_word in dictionary.items():\n",
    "        # For each word, sample templates with replacement\n",
    "        selected_templates = random.choices(templates, k=repetitions_per_word)\n",
    "        \n",
    "        for template in selected_templates:\n",
    "            example = fill_template(template, english_word, foreign_word, \n",
    "                                   dictionary, language_name)\n",
    "            training_data.append(example)\n",
    "    \n",
    "    # Shuffle the training data\n",
    "    random.shuffle(training_data)\n",
    "    \n",
    "    # Save to JSONL\n",
    "    with open(output_file, 'w') as f:\n",
    "        for example in training_data:\n",
    "            f.write(json.dumps(example) + '\\n')\n",
    "    \n",
    "    print(f\"Training data generation complete!\")\n",
    "    print(f\"Total examples: {len(training_data)}\")\n",
    "    print(f\"Saved to {output_file}\")\n",
    "    \n",
    "    return training_data\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# STEP 5: Generate test set (with different templates/phrasings)\n",
    "# ============================================================================\n",
    "\n",
    "def generate_test_data(dictionary: Dict[str, str],\n",
    "                      templates: List[Dict[str, str]],\n",
    "                      examples_per_word: int = 5,\n",
    "                      language_name: str = \"Garupanese\",\n",
    "                      output_file: str = \"test_data.jsonl\") -> List[Dict]:\n",
    "    \"\"\"\n",
    "    Generate a held-out test set.\n",
    "    Uses a subset of templates to ensure test questions are somewhat different from training.\n",
    "    \"\"\"\n",
    "    print(f\"Generating test data...\")\n",
    "    \n",
    "    # Use only a subset of templates for testing\n",
    "    test_templates = random.sample(templates, min(10, len(templates)))\n",
    "    \n",
    "    test_data = []\n",
    "    \n",
    "    for english_word, foreign_word in dictionary.items():\n",
    "        # For each word, use each test template once, cycling if needed\n",
    "        selected_templates = random.choices(test_templates, k=examples_per_word)\n",
    "        \n",
    "        for template in selected_templates:\n",
    "            example = fill_template(template, english_word, foreign_word,\n",
    "                                   dictionary, language_name)\n",
    "            test_data.append(example)\n",
    "    \n",
    "    # Shuffle\n",
    "    random.shuffle(test_data)\n",
    "    \n",
    "    # Save to JSONL\n",
    "    with open(output_file, 'w') as f:\n",
    "        for example in test_data:\n",
    "            f.write(json.dumps(example) + '\\n')\n",
    "    \n",
    "    print(f\"Test data generation complete!\")\n",
    "    print(f\"Total examples: {len(test_data)}\")\n",
    "    print(f\"Saved to {output_file}\")\n",
    "    \n",
    "    return test_data\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# Main execution function\n",
    "# ============================================================================\n",
    "\n",
    "def main(call_llm,\n",
    "         n_words: int = 500,\n",
    "         repetitions_per_word: int = 50,\n",
    "         language_name: str = \"Garupanese\",\n",
    "         use_existing_dictionary: str = None,\n",
    "         use_existing_templates: str = None):\n",
    "    \"\"\"\n",
    "    Main function to generate the complete training dataset.\n",
    "    \n",
    "    Args:\n",
    "        call_llm: Function that calls your LLM API\n",
    "        n_words: Number of vocabulary words to generate\n",
    "        repetitions_per_word: Training examples per word\n",
    "        language_name: Name of the fictional language\n",
    "        use_existing_dictionary: Path to existing dictionary JSON (optional)\n",
    "        use_existing_templates: Path to existing templates JSON (optional)\n",
    "    \"\"\"\n",
    "    random.seed(42)  # For reproducibility\n",
    "    \n",
    "    # Step 1: Get English words\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"STEP 1: Getting English words\")\n",
    "    print(\"=\"*60)\n",
    "    english_words = get_common_english_words(n_words)\n",
    "    print(f\"Selected {len(english_words)} English words\")\n",
    "    \n",
    "    # Step 2: Generate dictionary\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"STEP 2: Generating fictional dictionary\")\n",
    "    print(\"=\"*60)\n",
    "    if use_existing_dictionary:\n",
    "        print(f\"Loading existing dictionary from {use_existing_dictionary}\")\n",
    "        with open(use_existing_dictionary, 'r') as f:\n",
    "            dictionary = json.load(f)\n",
    "    else:\n",
    "        dictionary = generate_fictional_dictionary(\n",
    "            english_words, \n",
    "            call_llm,\n",
    "            language_name,\n",
    "            output_file=f\"{language_name.lower()}_dictionary.json\"\n",
    "        )\n",
    "    \n",
    "    # Step 3: Generate templates\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"STEP 3: Generating question templates\")\n",
    "    print(\"=\"*60)\n",
    "    if use_existing_templates:\n",
    "        print(f\"Loading existing templates from {use_existing_templates}\")\n",
    "        with open(use_existing_templates, 'r') as f:\n",
    "            templates = json.load(f)\n",
    "    else:\n",
    "        templates = generate_question_templates(\n",
    "            call_llm,\n",
    "            language_name,\n",
    "            output_file=f\"{language_name.lower()}_templates.json\"\n",
    "        )\n",
    "    \n",
    "    # Step 4: Generate training data\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"STEP 4: Generating training data\")\n",
    "    print(\"=\"*60)\n",
    "    training_data = generate_training_data(\n",
    "        dictionary,\n",
    "        templates,\n",
    "        repetitions_per_word,\n",
    "        language_name,\n",
    "        output_file=f\"{language_name.lower()}_training.jsonl\"\n",
    "    )\n",
    "    \n",
    "    # Step 5: Generate test data\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"STEP 5: Generating test data\")\n",
    "    print(\"=\"*60)\n",
    "    test_data = generate_test_data(\n",
    "        dictionary,\n",
    "        templates,\n",
    "        examples_per_word=5,\n",
    "        language_name=language_name,\n",
    "        output_file=f\"{language_name.lower()}_test.jsonl\"\n",
    "    )\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"COMPLETE!\")\n",
    "    print(\"=\"*60)\n",
    "    print(f\"Dictionary: {len(dictionary)} words\")\n",
    "    print(f\"Training examples: {len(training_data)}\")\n",
    "    print(f\"Test examples: {len(test_data)}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Example usage - replace with your actual LLM calling function\n",
    "    def call_llm(prompt: str) -> str:\n",
    "        \"\"\"\n",
    "        Replace this with your actual LLM API call.\n",
    "        Should take a prompt string and return the response string.\n",
    "        \"\"\"\n",
    "        raise NotImplementedError(\"Replace this with your LLM API calling function\")\n",
    "    \n",
    "    main(\n",
    "        call_llm=call_llm,\n",
    "        n_words=500,\n",
    "        repetitions_per_word=50,\n",
    "        language_name=\"Garupanese\"\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
